{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7822867",
   "metadata": {},
   "source": [
    "# Building the Roman Road Network using itiner-e dataset\n",
    "This notebook builds the Roman Road Network (RRN) using functions from `itinerex_clean_network.py` and the data originally released as part of the `[Nature](https://www.nature.com/articles/s41597-025-06140-z)` publication. \n",
    "\n",
    "It produces:\n",
    "- `roads_before_cleaning.html`: raw roads from GeoJSON (display only)\n",
    "- `roads_after_cleaning.html`: cleaned, noded, degree-2 simplified network with **node_id** and **edge_id** shown on the map\n",
    "- `G_clean_weighted_with_ids.pkl`: pickle containing the cleaned weighted graph + node/edge tables for mapping analysis results back to geometry/CRS.\n",
    "\n",
    "All metric operations run in **EPSG:3395**; maps are displayed in **EPSG:4326**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfdb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import folium\n",
    "import importlib\n",
    "import itinerex_clean_network as icn\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "from shapely.geometry import Point\n",
    "importlib.reload(icn)\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "GEOJSON_PATH = Path(\"17122148/itinere_roads.geojson\")\n",
    "\n",
    "# These tolerances are in meters (EPSG:3395).\n",
    "SNAP_TOL_M = 240.0\n",
    "MERGE_DEG1_TOL_M = 240.0\n",
    "\n",
    "# Constant-speed time weights (matches earlier baseline).\n",
    "BASE_SPEED_KMH = 2.0\n",
    "WEIGHT_MODE = \"time\"  # sets edge attribute 'weight' = travel time (seconds)\n",
    "\n",
    "OUT_BEFORE_HTML = Path(\"roads_before_cleaning.html\")\n",
    "OUT_AFTER_HTML = Path(\"roads_after_cleaning.html\")\n",
    "OUT_PICKLE = Path(\"G_clean_weighted_with_ids.pkl\")\n",
    "\n",
    "\n",
    "def _union_all(gs):\n",
    "    \"\"\"GeoSeries union helper compatible with Shapely 2 / older GeoPandas.\"\"\"\n",
    "    try:\n",
    "        return gs.union_all()\n",
    "    except Exception:\n",
    "        return gs.unary_union\n",
    "\n",
    "\n",
    "def _node_id_mapping(G: nx.Graph):\n",
    "    \"\"\"Assign stable node_ids (1..N) by sorting coordinates.\"\"\"\n",
    "    nodes = [(float(x), float(y)) for (x, y) in G.nodes()]\n",
    "    nodes_sorted = sorted(nodes, key=lambda xy: (xy[0], xy[1]))\n",
    "    node_to_id = {xy: i + 1 for i, xy in enumerate(nodes_sorted)}\n",
    "    id_to_node = {i: xy for xy, i in node_to_id.items()}\n",
    "    return node_to_id, id_to_node\n",
    "\n",
    "\n",
    "def _edge_id_mapping(G: nx.Graph, node_to_id: dict[tuple[float, float], int]):\n",
    "    \"\"\"Assign stable edge_ids (1..M) by sorting undirected (u_id, v_id).\"\"\"\n",
    "    pairs = []\n",
    "    for u, v in G.edges():\n",
    "        uid = int(node_to_id[(float(u[0]), float(u[1]))])\n",
    "        vid = int(node_to_id[(float(v[0]), float(v[1]))])\n",
    "        a, b = (uid, vid) if uid <= vid else (vid, uid)\n",
    "        pairs.append((a, b, (u, v)))\n",
    "    pairs_sorted = sorted(pairs, key=lambda t: (t[0], t[1]))\n",
    "    edge_key_to_id = {(a, b): i + 1 for i, (a, b, _) in enumerate(pairs_sorted)}\n",
    "    return edge_key_to_id\n",
    "\n",
    "\n",
    "def graph_to_tables(G: nx.Graph, crs_3395: str = \"EPSG:3395\"):\n",
    "    \"\"\"Return (nodes_gdf_3395, edges_gdf_3395, nodes_gdf_4326, edges_gdf_4326).\"\"\"\n",
    "    node_to_id, id_to_node = _node_id_mapping(G)\n",
    "    edge_key_to_id = _edge_id_mapping(G, node_to_id)\n",
    "\n",
    "    # Nodes\n",
    "    deg = dict(G.degree())\n",
    "    rows_n = []\n",
    "    for xy, node_id in node_to_id.items():\n",
    "        x, y = float(xy[0]), float(xy[1])\n",
    "        rows_n.append({\n",
    "            \"node_id\": int(node_id),\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"degree\": int(deg.get(xy, 0)),\n",
    "        })\n",
    "    nodes_3395 = gpd.GeoDataFrame(\n",
    "        rows_n,\n",
    "        geometry=gpd.points_from_xy([r[\"x\"] for r in rows_n], [r[\"y\"] for r in rows_n]),\n",
    "        crs=crs_3395,\n",
    "    )\n",
    "    nodes_4326 = nodes_3395.to_crs(epsg=4326)\n",
    "\n",
    "    # Edges (requires 'geometry' on graph edges)\n",
    "    rows_e = []\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        u = (float(u[0]), float(u[1]))\n",
    "        v = (float(v[0]), float(v[1]))\n",
    "        uid = int(node_to_id[u])\n",
    "        vid = int(node_to_id[v])\n",
    "        a, b = (uid, vid) if uid <= vid else (vid, uid)\n",
    "        edge_id = int(edge_key_to_id[(a, b)])\n",
    "        rows_e.append({\n",
    "            \"edge_id\": edge_id,\n",
    "            \"u_id\": uid,\n",
    "            \"v_id\": vid,\n",
    "            \"weight\": float(d.get(\"weight\", 1.0)),\n",
    "            \"time_s\": float(d.get(\"time_s\", d.get(\"weight\", np.nan))),\n",
    "            \"dist_m\": float(d.get(\"dist_m\", np.nan)),\n",
    "            \"geometry\": d.get(\"geometry\"),\n",
    "        })\n",
    "    edges_3395 = gpd.GeoDataFrame(rows_e, crs=crs_3395)\n",
    "    edges_3395 = edges_3395[edges_3395.geometry.notna() & ~edges_3395.geometry.is_empty].copy()\n",
    "    edges_4326 = edges_3395.to_crs(epsg=4326)\n",
    "\n",
    "    return nodes_3395, edges_3395, nodes_4326, edges_4326, node_to_id, id_to_node, edge_key_to_id\n",
    "\n",
    "\n",
    "def save_before_map(roads_4326: gpd.GeoDataFrame, out_html: Path, simplify_tol_m: float = 50.0):\n",
    "    \"\"\"Save a lightweight BEFORE map.\n",
    "\n",
    "    The raw roads are often too large to embed feature-by-feature in a Folium HTML.\n",
    "    We project to EPSG:3395, simplify in meters, dissolve into one geometry, then map that.\n",
    "    \"\"\"\n",
    "    if roads_4326 is None or len(roads_4326) == 0:\n",
    "        raise ValueError(\"No roads to plot\")\n",
    "\n",
    "    roads_m = roads_4326.to_crs(epsg=3395)\n",
    "    simp = roads_m.geometry.simplify(float(simplify_tol_m), preserve_topology=True)\n",
    "    merged_m = _union_all(simp)\n",
    "    merged_4326 = gpd.GeoDataFrame({\"geometry\": [merged_m]}, crs=\"EPSG:3395\").to_crs(epsg=4326)\n",
    "\n",
    "    center = merged_4326.geometry.iloc[0].centroid\n",
    "    m = folium.Map(location=[float(center.y), float(center.x)], zoom_start=6, tiles=\"CartoDB positron\")\n",
    "    folium.GeoJson(merged_4326.__geo_interface__, name=\"Roads (raw, simplified)\").add_to(m)\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    m.save(str(out_html))\n",
    "    return out_html\n",
    "\n",
    "\n",
    "def save_after_map(edges_4326: gpd.GeoDataFrame, nodes_4326: gpd.GeoDataFrame, out_html: Path):\n",
    "    if (edges_4326 is None or len(edges_4326) == 0) and (nodes_4326 is None or len(nodes_4326) == 0):\n",
    "        raise ValueError(\"No cleaned nodes/edges to plot\")\n",
    "    if edges_4326 is not None and len(edges_4326):\n",
    "        center = _union_all(edges_4326.geometry).centroid\n",
    "    else:\n",
    "        center = _union_all(nodes_4326.geometry).centroid\n",
    "    m = folium.Map(location=[float(center.y), float(center.x)], zoom_start=6, tiles=\"CartoDB positron\")\n",
    "\n",
    "    fg_edges = folium.FeatureGroup(name=\"Edges (cleaned)\", show=True)\n",
    "    fg_nodes = folium.FeatureGroup(name=\"Nodes (cleaned)\", show=True)\n",
    "    m.add_child(fg_edges)\n",
    "    m.add_child(fg_nodes)\n",
    "\n",
    "    use_edges = edges_4326.copy()\n",
    "    for col in [\"edge_id\", \"u_id\", \"v_id\"]:\n",
    "        use_edges[col] = use_edges[col].astype(int)\n",
    "    if \"time_s\" in use_edges.columns:\n",
    "        use_edges[\"time_s\"] = use_edges[\"time_s\"].astype(float)\n",
    "    if \"dist_m\" in use_edges.columns:\n",
    "        use_edges[\"dist_m\"] = use_edges[\"dist_m\"].astype(float)\n",
    "    folium.GeoJson(\n",
    "        use_edges.__geo_interface__,\n",
    "        name=\"Edges (cleaned)\",\n",
    "        tooltip=folium.GeoJsonTooltip(\n",
    "            fields=[\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\"],\n",
    "            aliases=[\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\"],\n",
    "            sticky=True,\n",
    "        ),\n",
    "    ).add_to(fg_edges)\n",
    "\n",
    "    for row in nodes_4326.itertuples(index=False):\n",
    "        lat = float(row.geometry.y)\n",
    "        lon = float(row.geometry.x)\n",
    "        folium.CircleMarker(\n",
    "            location=(lat, lon),\n",
    "            radius=3,\n",
    "            color=\"#2ca02c\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.9,\n",
    "            tooltip=f\"node_id={int(row.node_id)} deg={int(row.degree)}\",\n",
    "        ).add_to(fg_nodes)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    m.save(str(out_html))\n",
    "    return out_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554b581",
   "metadata": {},
   "source": [
    "# 1) Load raw roads + BEFORE map\n",
    "Loads the input roads GeoJSON, projects to EPSG:3395 for metric operations, and saves a raw “before cleaning” HTML map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bb0641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roads_4326: 14769 features\n",
      "roads_3395 CRS: EPSG:3395\n",
      "Saved: roads_before_cleaning.html\n"
     ]
    }
   ],
   "source": [
    "# Load (keep a 4326 copy for mapping)\n",
    "roads_4326 = gpd.read_file(GEOJSON_PATH)\n",
    "roads_4326 = roads_4326[roads_4326.geometry.notna() & ~roads_4326.geometry.is_empty].copy()\n",
    "roads_4326 = roads_4326[roads_4326.geometry.geom_type.isin([\"LineString\", \"MultiLineString\"])].copy()\n",
    "roads_4326 = roads_4326.reset_index(drop=True)\n",
    "\n",
    "# Project for cleaning operations\n",
    "roads_3395 = roads_4326.to_crs(epsg=3395)\n",
    "print(\"roads_4326:\", len(roads_4326), \"features\")\n",
    "print(\"roads_3395 CRS:\", roads_3395.crs)\n",
    "\n",
    "out_before = save_before_map(roads_4326, OUT_BEFORE_HTML)\n",
    "print(\"Saved:\", out_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5bbbd7",
   "metadata": {},
   "source": [
    "# 2) Clean rebuild + AFTER map + export\n",
    "Builds a cleaned topology from the raw GeoJSON using `itinerex_clean_network.build_clean_network_from_geojson()`, assigns stable `node_id`/`edge_id`, saves an “after cleaning” HTML map with those IDs, and exports everything as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f659b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] load...\n",
      "[2/10] prepare...\n",
      "[3/10] snap...\n",
      "Snapping line endpoints to nearby linework\n",
      "[4/10] node...\n",
      "[5/10] segmentize...\n",
      "Converting lines to segments\n",
      "[6/10] graph...\n",
      "Building graph from segments\n",
      "[7/10] merge_deg1...\n",
      "[8/10] simplify_deg2...\n",
      "Simplifying degree-2 nodes\n",
      "{'snap_tol_m': 240.0, 'near_miss_before': {'skipped': 1}, 'near_miss_after': {'skipped': 1}, 'noded_lines': 16851, 'segments': 1001619, 'graph_nodes': 8460, 'graph_edges': 12849, 'deg2_nodes': 0, 'deg1_nodes': 833, 'timings_s': {'load': 1.8017390000022715, 'prepare': 0.027291874997899868, 'snap': 1.506065875000786, 'node': 1.026009500004875, 'segmentize': 4.102779790999193, 'graph': 10.99082887500117, 'merge_deg1': 16.527879458000825, 'simplify_deg2': 14.977518125000643}, 'snap_method': 'endpoints', 'diagnose': False, 'diagnose_max_endpoints': None, 'merge_deg1': {'enabled': 1, 'deg1_before': 998, 'deg1_after': 829, 'clusters': 81, 'merged_nodes': 173}, 'base_speed_kmh': 2.0, 'weight_mode': 'time'}\n",
      "G_clean: 8460 nodes; 12849 edges\n",
      "Example edge attrs: {'weight': 4021.520454095041, 'dist_m': 2234.1780300528008, 'time_s': 4021.520454095041, 'geometry': <LINESTRING (2595776.094 4597595.392, 2595762.057 4597411.293, 2595687.194 4...>}\n",
      "nodes_clean_3395: 8460 rows\n",
      "edges_clean_3395: 12849 rows\n"
     ]
    }
   ],
   "source": [
    "# Build cleaned network (EPSG:3395 metric topology)\n",
    "res = icn.build_clean_network_from_geojson(\n",
    "    str(GEOJSON_PATH),\n",
    "    snap_tol_m=float(SNAP_TOL_M),\n",
    "    snap_method=\"endpoints\",\n",
    "    diagnose=False,\n",
    "    merge_deg1_tol_m=float(MERGE_DEG1_TOL_M),\n",
    "    merge_deg1_min_samples=2,\n",
    "    simplify_deg2=True,\n",
    "    base_speed_kmh=float(BASE_SPEED_KMH),\n",
    "    weight_mode=str(WEIGHT_MODE),\n",
    "    show_progress=True,\n",
    " )\n",
    "\n",
    "print(res.diagnostics)\n",
    "\n",
    "G_clean: nx.Graph = res.graph\n",
    "segments_clean_3395: gpd.GeoDataFrame = res.segments_m\n",
    "noded_lines_clean_3395: gpd.GeoDataFrame = res.noded_lines_m\n",
    "\n",
    "print(\"G_clean:\", G_clean.number_of_nodes(), \"nodes;\", G_clean.number_of_edges(), \"edges\")\n",
    "print(\"Example edge attrs:\", next(iter(G_clean.edges(data=True)))[2])\n",
    "\n",
    "# Assign stable IDs and create node/edge tables (both 3395 + 4326)\n",
    "nodes_clean_3395, edges_clean_3395, nodes_clean_4326, edges_clean_4326, node_to_id, id_to_node, edge_key_to_id = graph_to_tables(\n",
    "    G_clean, crs_3395=\"EPSG:3395\"\n",
    " )\n",
    "\n",
    "# Attach node_id/edge_id onto the graph too (for routing + analysis)\n",
    "for xy, node_id in node_to_id.items():\n",
    "    if xy in G_clean:\n",
    "        G_clean.nodes[xy][\"node_id\"] = int(node_id)\n",
    "\n",
    "for u, v, d in G_clean.edges(data=True):\n",
    "    uid = int(node_to_id[(float(u[0]), float(u[1]))])\n",
    "    vid = int(node_to_id[(float(v[0]), float(v[1]))])\n",
    "    a, b = (uid, vid) if uid <= vid else (vid, uid)\n",
    "    d[\"edge_id\"] = int(edge_key_to_id[(a, b)])\n",
    "    d[\"u_id\"] = uid\n",
    "    d[\"v_id\"] = vid\n",
    "\n",
    "print(\"nodes_clean_3395:\", len(nodes_clean_3395), \"rows\")\n",
    "print(\"edges_clean_3395:\", len(edges_clean_3395), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ee111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: roads_after_cleaning.html\n"
     ]
    }
   ],
   "source": [
    "# Save AFTER map (cleaned network) with node_id / edge_id tooltips\n",
    "out_after = save_after_map(edges_clean_4326, nodes_clean_4326, OUT_AFTER_HTML)\n",
    "print(\"Saved:\", out_after)\n",
    "\n",
    "# # Display inline map object\n",
    "# m_after = folium.Map(location=[float(nodes_clean_4326.geometry.y.mean()), float(nodes_clean_4326.geometry.x.mean())], zoom_start=6, tiles=\"CartoDB positron\")\n",
    "# folium.GeoJson(\n",
    "#     edges_clean_4326.__geo_interface__,\n",
    "#     name=\"Edges (cleaned)\",\n",
    "#     tooltip=folium.GeoJsonTooltip(fields=[\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\"], sticky=True),\n",
    "# ).add_to(m_after)\n",
    "# for row in nodes_clean_4326.itertuples(index=False):\n",
    "#     folium.CircleMarker(\n",
    "#         location=(float(row.geometry.y), float(row.geometry.x)),\n",
    "#         radius=3,\n",
    "#         color=\"#2ca02c\",\n",
    "#         fill=True,\n",
    "#         fill_opacity=0.9,\n",
    "#         tooltip=f\"node_id={int(row.node_id)} deg={int(row.degree)}\",\n",
    "#     ).add_to(m_after)\n",
    "# folium.LayerControl(collapsed=False).add_to(m_after)\n",
    "# m_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e32713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes                              : 8460\n",
      "edges                              : 12849\n",
      "avg_degree                         : 3.0375886524822695\n",
      "avg_weighted_degree                : 167930.63592041272\n",
      "connected_components               : 12\n",
      "largest_component_nodes            : 7612\n",
      "largest_component_edges            : 11693\n",
      "largest_component_fraction_of_nodes: 0.8997635933806146\n"
     ]
    }
   ],
   "source": [
    "def graph_stats(G: nx.Graph, weight: str | None = \"weight\"):\n",
    "    \"\"\"Basic graph stats + (optional) weighted degree (strength).\"\"\"\n",
    "    n = int(G.number_of_nodes())\n",
    "    m = int(G.number_of_edges())\n",
    "    avg_deg = (2.0 * m / n) if n else 0.0\n",
    "\n",
    "    if weight is None:\n",
    "        wdeg = dict(G.degree())\n",
    "    else:\n",
    "        if m and not any((weight in d) for _, _, d in G.edges(data=True)):\n",
    "            print(f\"WARNING: edge attribute '{weight}' not found on any edge; weighted degree will equal unweighted degree.\")\n",
    "        wdeg = dict(G.degree(weight=weight))\n",
    "    avg_wdeg = float(np.mean(list(wdeg.values()))) if n else 0.0\n",
    "\n",
    "    comps = list(nx.connected_components(G))\n",
    "    num_cc = int(len(comps))\n",
    "    largest_cc_size = int(max((len(c) for c in comps), default=0))\n",
    "    if largest_cc_size:\n",
    "        largest_nodes = max(comps, key=len)\n",
    "        G_lcc = G.subgraph(largest_nodes)\n",
    "        lcc_edges = int(G_lcc.number_of_edges())\n",
    "        lcc_frac = float(largest_cc_size / n)\n",
    "    else:\n",
    "        lcc_edges = 0\n",
    "        lcc_frac = 0.0\n",
    "\n",
    "    return {\n",
    "        \"nodes\": n,\n",
    "        \"edges\": m,\n",
    "        \"avg_degree\": float(avg_deg),\n",
    "        \"avg_weighted_degree\": float(avg_wdeg),\n",
    "        \"connected_components\": num_cc,\n",
    "        \"largest_component_nodes\": largest_cc_size,\n",
    "        \"largest_component_edges\": lcc_edges,\n",
    "        \"largest_component_fraction_of_nodes\": float(lcc_frac),\n",
    "    }\n",
    "\n",
    "stats = graph_stats(G_clean, weight=\"weight\")\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k:35s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b83d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/nk821/Documents/GitHub/itinereX/G_clean_weighted_with_ids.pkl\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned weighted network + mapping tables\n",
    "\n",
    "# NOTE on portability:\n",
    "# Pickling raw NetworkX graphs can be brittle across Python/NetworkX versions.\n",
    "# This export is reconstruction-friendly: it stores node/edge tables + an edge list.\n",
    "\n",
    "edges_export_3395 = edges_clean_3395.copy()\n",
    "try:\n",
    "    edges_export_3395[\"geometry_wkt\"] = edges_export_3395.geometry.to_wkt()\n",
    "except Exception:\n",
    "    edges_export_3395[\"geometry_wkt\"] = edges_export_3395.geometry.apply(lambda g: g.wkt if g is not None else None)\n",
    "\n",
    "nodes_export_3395 = nodes_clean_3395.copy()\n",
    "try:\n",
    "    nodes_export_3395[\"geometry_wkt\"] = nodes_export_3395.geometry.to_wkt()\n",
    "except Exception:\n",
    "    nodes_export_3395[\"geometry_wkt\"] = nodes_export_3395.geometry.apply(lambda g: g.wkt if g is not None else None)\n",
    "\n",
    "export = {\n",
    "    \"crs_metric\": \"EPSG:3395\",\n",
    "    \"crs_map\": \"EPSG:4326\",\n",
    "    \"params\": {\n",
    "        \"geojson\": str(GEOJSON_PATH),\n",
    "        \"snap_tol_m\": float(SNAP_TOL_M),\n",
    "        \"merge_deg1_tol_m\": float(MERGE_DEG1_TOL_M),\n",
    "        \"base_speed_kmh\": float(BASE_SPEED_KMH),\n",
    "        \"weight_mode\": str(WEIGHT_MODE),\n",
    "    },\n",
    "    # Full GeoDataFrames (with shapely geometries)\n",
    "    \"nodes_3395\": nodes_export_3395,\n",
    "    \"edges_3395\": edges_export_3395,\n",
    "    \"nodes_4326\": nodes_clean_4326,\n",
    "    \"edges_4326\": edges_clean_4326,\n",
    "    # Reconstruction-friendly tables (no shapely dependency required if using WKT)\n",
    "    \"node_table\": nodes_export_3395.drop(columns=[\"geometry\"], errors=\"ignore\"),\n",
    "    \"edge_table\": edges_export_3395.drop(columns=[\"geometry\"], errors=\"ignore\"),\n",
    "    # Stable mappings\n",
    "    \"node_to_id\": node_to_id,\n",
    "    \"id_to_node\": id_to_node,\n",
    "}\n",
    "\n",
    "with open(OUT_PICKLE, \"wb\") as f:\n",
    "    pickle.dump(export, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saved:\", OUT_PICKLE.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73fbac7",
   "metadata": {},
   "source": [
    "# 4) Province Overlay & Sub-Networks\n",
    "\n",
    "Loads Roman province polygons from the shapefile in `provinces/provinces.shp`, of Roman provinces in 200 CE (peak Roman Empire under the Severan dynasty), based on 'roman-empire-ce-200-provinces.geojson' published by The Ancient World Mapping Centre and corrected by Adam Pazout in 2023. https://github.com/AWMC/geodata/tree/master/Cultural-Data/political_shading/roman_empire_ce_200_provinces. The provinces are overlaid on the roman road network and corresponding provicial road networks are constructed. \n",
    "\n",
    "**Outputs:**\n",
    "| File | Contents |\n",
    "|---|---|\n",
    "| `roads_with_provinces_nodes.html` | Maps marking each province and the road network in each province where nodes are intersections and edges are the road geometries |\n",
    "| `G_clean_weighted_edges_with_province.csv` | Edge list for the weighted network: `edge_id`, (`u_id`,`v_id`), `time_s`, and province assignment |\n",
    "| `crossing_edges.geojson` | Edges whose **endpoints** fall in **different** provinces (excluded from sub-networks) |\n",
    "| `outside_provinces_edges.geojson` | Edges that cannot be assigned to any province (excluded from sub-networks) |\n",
    "| `province_subnetworks.pkl` | Dict with `province_subgraphs` (NetworkX), `province_edge_tables` (GeoDataFrames), `crossing_edge_ids`, `outside_edge_ids`, `edge_province_map` |\n",
    "\n",
    "**Classification logic:**\n",
    "- **Province assignment:** assign each edge to the (most specific) province containing its midpoint; if the midpoint is not inside any polygon, fall back to the province with the longest overlap length.\n",
    "- **Crossing edges (excluded):** an edge is marked crossing if its **start** and **end** points fall in **different** provinces.\n",
    "- **Outside edges (excluded):** an edge is outside if it cannot be assigned to any province by midpoint or overlap fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3094669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 57 province polygons from provinces/provinces.shp\n",
      "Unique province names: 57\n",
      "Province CRS: EPSG:4326\n",
      "\n",
      "Edge assignment\n",
      "  Resolved by midpoint (most-specific): 12791\n",
      "  Needing overlap fallback           : 58\n",
      "  Resolved by overlap fallback         : 19\n",
      "\n",
      "Edge classification\n",
      "  Total edges                  : 12849\n",
      "  Within-province (kept)       : 12173\n",
      "  Crossing border (excluded)   : 637\n",
      "  Outside all polygons         : 39\n",
      "\n",
      "Saved weighted edge list → G_clean_weighted_edges_with_province.csv (12849 edges)\n",
      "\n",
      "Saved crossing edges          → crossing_edges.geojson  (637 edges)\n",
      "Saved outside-province edges  → outside_provinces_edges.geojson   (39 edges)\n",
      "\n",
      "Provinces with assigned edges: 57\n",
      "\n",
      "Province                             Nodes   Edges  Components\n",
      "-----------------------------------------------------------------\n",
      "Achaia                                 363     525           3\n",
      "Aegyptus                               176     265           1\n",
      "Aemilia (Regio VIII)                    28      35           2\n",
      "Africa Proconsularis                   337     531           1\n",
      "Alpes Cottiae                            6       5           1\n",
      "Alpes Graiae                             5       5           1\n",
      "Alpes Maritimae                          3       2           1\n",
      "Alpes Poeninae                           3       2           1\n",
      "Apulia et Calabria (Regio II)           76     108           1\n",
      "Aquitania                              209     317           1\n",
      "Arabia                                 143     206           3\n",
      "Asia                                   292     420           1\n",
      "Baetica                                128     176           1\n",
      "Belgica                                355     572           1\n",
      "Bithynia et Pontus                      70      94           1\n",
      "Britannia                              672     935           1\n",
      "Bruttium et Lucania (Regio III)         52      75           1\n",
      "Cappadocia                             201     296           1\n",
      "Cilicia                                 83     111           1\n",
      "Corsica                                  2       1           1\n",
      "Creta                                   24      26           1\n",
      "Cyprus                                  75     100           1\n",
      "Cyrene                                  59      87           1\n",
      "Dacia                                  124     168           1\n",
      "Dalmatia                               172     231           2\n",
      "Epirus                                  47      58           2\n",
      "Etruria (Regio VII)                     24      28           1\n",
      "Galatia                                123     167           1\n",
      "Germania Inferior                      250     346           1\n",
      "Germania Superior                      182     258           1\n",
      "Hispania Citerior                      787    1143           2\n",
      "Iudaea                                 111     164           1\n",
      "Latium et Campania (Regio I)           127     187           2\n",
      "Liguria (Regio IX)                      13      15           2\n",
      "Lugdunensis                            560     853           1\n",
      "Lusitania                              234     354           1\n",
      "Lycia et Pamphylia                     214     299           1\n",
      "Macedonia                              121     170           1\n",
      "Mauretania Caesariensis                286     439           1\n",
      "Mauretania Tingitana                    31      43           1\n",
      "Moesia Inferior                        136     196           1\n",
      "Moesia Superior                        115     156           1\n",
      "Narbonensis                            170     242           2\n",
      "Noricum                                 70      93           2\n",
      "Numidia                                229     340           1\n",
      "Pannonia Inferior                       53      68           1\n",
      "Pannonia Superior                      127     178           1\n",
      "Picenum (Regio V)                        9      10           1\n",
      "Raetia                                 118     161           2\n",
      "Samnium (Regio IV)                      17      17           1\n",
      "Sardinia                                26      39           1\n",
      "Sicilia                                 23      29           1\n",
      "Syria                                  182     269           1\n",
      "Thracia                                242     357           1\n",
      "Transpadana (Regio XI)                  27      40           1\n",
      "Umbria (Regio VI)                        7       6           2\n",
      "Venetia et Histria (Regio X)           107     155           1\n",
      "\n",
      "Saved province sub-networks → province_subnetworks.pkl\n",
      "Saved province overlay + nodes → roads_with_provinces_nodes.html\n"
     ]
    }
   ],
   "source": [
    "# --- Province Overlay & Sub-Networks (Shapefile only) ---\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "PROVINCES_PATH          = Path(\"provinces/provinces.shp\")\n",
    "OUT_PROVINCE_MAP_NODES  = Path(\"roads_with_provinces_nodes.html\")\n",
    "OUT_WEIGHTED_EDGES_PROV = Path(\"G_clean_weighted_edges_with_province.csv\")\n",
    "OUT_CROSSING_EDGES      = Path(\"crossing_edges.geojson\")\n",
    "OUT_OUTSIDE_EDGES       = Path(\"outside_provinces_edges.geojson\")\n",
    "OUT_PROVINCE_NETWORKS   = Path(\"province_subnetworks.pkl\")\n",
    "IN_CLEAN_PICKLE = Path(\"G_clean_weighted_with_ids.pkl\")\n",
    "_required_vars = [\"edges_clean_3395\", \"edges_clean_4326\", \"nodes_clean_4326\", \"G_clean\"]\n",
    "_missing = [v for v in _required_vars if v not in globals()]\n",
    "if _missing:\n",
    "    if not IN_CLEAN_PICKLE.exists():\n",
    "        raise RuntimeError(\n",
    "            \"Missing in-kernel variables: \" + \", \".join(_missing) + \"\\n\"\n",
    "            \"Run the network cleaning cells above first, or ensure G_clean_weighted_with_ids.pkl exists.\"\n",
    "        )\n",
    "    data = pickle.load(IN_CLEAN_PICKLE.open(\"rb\"))\n",
    "    # Tables for mapping + province overlay\n",
    "    if \"nodes_clean_3395\" not in globals():\n",
    "        nodes_clean_3395 = data[\"nodes_3395\"]\n",
    "    if \"edges_clean_3395\" not in globals():\n",
    "        edges_clean_3395 = data[\"edges_3395\"]\n",
    "    if \"nodes_clean_4326\" not in globals():\n",
    "        nodes_clean_4326 = data[\"nodes_4326\"]\n",
    "    if \"edges_clean_4326\" not in globals():\n",
    "        edges_clean_4326 = data[\"edges_4326\"]\n",
    "    node_to_id = data.get(\"node_to_id\")\n",
    "    id_to_node = data.get(\"id_to_node\")\n",
    "\n",
    "    # Reconstruct G_clean (only if missing) from saved id mappings + tables\n",
    "    if \"G_clean\" not in globals():\n",
    "        if id_to_node is None:\n",
    "            raise RuntimeError(\"Pickle is missing id_to_node; can't reconstruct G_clean.\")\n",
    "        node_table = data.get(\"node_table\")\n",
    "        edge_table = data.get(\"edge_table\")\n",
    "        if node_table is None or edge_table is None:\n",
    "            raise RuntimeError(\"Pickle missing node_table/edge_table; can't reconstruct G_clean.\")\n",
    "\n",
    "        G_clean = nx.Graph()\n",
    "        for row in node_table.itertuples(index=False):\n",
    "            nid = int(getattr(row, \"node_id\"))\n",
    "            nkey = id_to_node.get(nid)\n",
    "            if nkey is None:\n",
    "                continue\n",
    "            G_clean.add_node(\n",
    "                nkey,\n",
    "                node_id=nid,\n",
    "                x=float(getattr(row, \"x\")),\n",
    "                y=float(getattr(row, \"y\")),\n",
    "                degree=int(getattr(row, \"degree\")),\n",
    "            )\n",
    "        for row in edge_table.itertuples(index=False):\n",
    "            ukey = id_to_node.get(int(getattr(row, \"u_id\")))\n",
    "            vkey = id_to_node.get(int(getattr(row, \"v_id\")))\n",
    "            if ukey is None or vkey is None:\n",
    "                continue\n",
    "            G_clean.add_edge(\n",
    "                ukey,\n",
    "                vkey,\n",
    "                edge_id=int(getattr(row, \"edge_id\")),\n",
    "                weight=float(getattr(row, \"weight\")),\n",
    "                time_s=float(getattr(row, \"time_s\")),\n",
    "                dist_m=float(getattr(row, \"dist_m\")),\n",
    "            )\n",
    "        print(f\"[Loaded from {IN_CLEAN_PICKLE}] Reconstructed G_clean: {G_clean.number_of_nodes()} nodes; {G_clean.number_of_edges()} edges\")\n",
    "\n",
    "# ── 1. Load province polygons (shapefile) ─────────────────────────────────────\n",
    "_provinces_raw = gpd.read_file(PROVINCES_PATH)\n",
    "_provinces_raw = _provinces_raw[_provinces_raw.geometry.notna() & ~_provinces_raw.geometry.is_empty].copy()\n",
    "\n",
    "if _provinces_raw.crs is None:\n",
    "    raise ValueError(\"Province shapefile has no CRS; please ensure .prj is present.\")\n",
    "\n",
    "# Prefer explicit field name; otherwise try to auto-detect a reasonable name column\n",
    "_name_col = None\n",
    "if \"province\" in _provinces_raw.columns:\n",
    "    _name_col = \"province\"\n",
    "else:\n",
    "    _candidates = [c for c in _provinces_raw.columns if c != \"geometry\" and (\"name\" in str(c).lower() or \"prov\" in str(c).lower())]\n",
    "    if _candidates:\n",
    "        _name_col = _candidates[0]\n",
    "    else:\n",
    "        _obj_cols = [c for c in _provinces_raw.columns if c != \"geometry\" and str(_provinces_raw[c].dtype) == \"object\"]\n",
    "        if _obj_cols:\n",
    "            _name_col = _obj_cols[0]\n",
    "\n",
    "if _name_col is None:\n",
    "    raise ValueError(f\"Couldn't find a province name column in shapefile. Columns: {list(_provinces_raw.columns)}\")\n",
    "\n",
    "_provinces_raw[\"name\"] = _provinces_raw[_name_col].astype(str)\n",
    "provinces_4326 = _provinces_raw[[\"name\", \"geometry\"]].copy()\n",
    "\n",
    "# Dissolve to one row per province name (handles multi-part provinces cleanly)\n",
    "provinces_4326 = provinces_4326.dissolve(by=\"name\", as_index=False)\n",
    "\n",
    "# Make geometry valid where possible (avoid topology errors during intersections)\n",
    "try:\n",
    "    provinces_4326[\"geometry\"] = provinces_4326.geometry.make_valid()\n",
    "except Exception:\n",
    "    provinces_4326[\"geometry\"] = provinces_4326.buffer(0)\n",
    "\n",
    "provinces_4326 = provinces_4326.to_crs(epsg=4326)\n",
    "print(f\"Loaded {len(provinces_4326)} province polygons from {PROVINCES_PATH}\")\n",
    "print(f\"Unique province names: {provinces_4326['name'].nunique()}\")\n",
    "print(f\"Province CRS: {provinces_4326.crs}\")\n",
    "\n",
    "# ── 2. Assign edges to provinces (most-specific midpoint) + crossing detection ──\n",
    "provinces_3395 = provinces_4326.to_crs(epsg=3395).copy()\n",
    "provinces_3395[\"_prov_area\"] = provinces_3395.geometry.area.astype(float)\n",
    "edges_3395 = edges_clean_3395[[\"edge_id\", \"geometry\"]].copy()\n",
    "edges_3395[\"edge_id\"] = edges_3395[\"edge_id\"].astype(int)\n",
    "\n",
    "def _as_linestring(geom):\n",
    "    if geom is None or geom.is_empty:\n",
    "        return geom\n",
    "    gt = getattr(geom, \"geom_type\", None)\n",
    "    if gt == \"LineString\":\n",
    "        return geom\n",
    "    if gt == \"MultiLineString\":\n",
    "        try:\n",
    "            return max(list(geom.geoms), key=lambda g: g.length)\n",
    "        except Exception:\n",
    "            return geom\n",
    "    return geom\n",
    "\n",
    "def _midpoint(geom):\n",
    "    geom = _as_linestring(geom)\n",
    "    try:\n",
    "        return geom.interpolate(0.5, normalized=True)\n",
    "    except Exception:\n",
    "        return geom.centroid\n",
    "\n",
    "def _endpoints(geom):\n",
    "    geom = _as_linestring(geom)\n",
    "    try:\n",
    "        xs, ys = geom.coords[0]\n",
    "        xe, ye = geom.coords[-1]\n",
    "        return Point(xs, ys), Point(xe, ye)\n",
    "    except Exception:\n",
    "        c = geom.centroid\n",
    "        return c, c\n",
    "\n",
    "def _pick_most_specific(join_df, group_cols, name_col, area_col):\n",
    "    if join_df is None or len(join_df) == 0:\n",
    "        return {}\n",
    "    use = join_df[join_df[name_col].notna()].copy()\n",
    "    if len(use) == 0:\n",
    "        return {}\n",
    "    use[area_col] = use[area_col].astype(float)\n",
    "    use = use.sort_values([*group_cols, area_col], ascending=True)\n",
    "    picked = use.groupby(group_cols)[name_col].first()\n",
    "    return picked.to_dict()\n",
    "\n",
    "# --- Midpoint-based province assignment (most-specific) ---\n",
    "midpoints_3395 = gpd.GeoDataFrame(\n",
    "    {\"edge_id\": edges_3395[\"edge_id\"].values},\n",
    "    geometry=[_midpoint(g) for g in edges_3395[\"geometry\"]],\n",
    "    crs=\"EPSG:3395\",\n",
    ")\n",
    "mid_join = gpd.sjoin(\n",
    "    midpoints_3395,\n",
    "    provinces_3395[[\"name\", \"_prov_area\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"intersects\",\n",
    ")\n",
    "name_col_mid = \"name_right\" if \"name_right\" in mid_join.columns else \"name\"\n",
    "area_col_mid = \"_prov_area_right\" if \"_prov_area_right\" in mid_join.columns else \"_prov_area\"\n",
    "mid_best = _pick_most_specific(mid_join, [\"edge_id\"], name_col_mid, area_col_mid)\n",
    "unresolved_ids = set(edges_3395[\"edge_id\"].tolist()) - set(mid_best.keys())\n",
    "print(f\"\\nEdge assignment\")\n",
    "print(f\"  Resolved by midpoint (most-specific): {len(mid_best)}\")\n",
    "print(f\"  Needing overlap fallback           : {len(unresolved_ids)}\")\n",
    "\n",
    "# --- Fallback: longest overlap length (tie-break by smallest polygon area) ---\n",
    "fallback_map = {}  # edge_id -> province_name\n",
    "if unresolved_ids:\n",
    "    unresolved_edges = edges_3395[edges_3395[\"edge_id\"].isin(unresolved_ids)].copy()\n",
    "    prov_sindex = provinces_3395.sindex\n",
    "    prov_areas = provinces_3395[\"_prov_area\"].astype(float).tolist()\n",
    "    eps = 1e-6\n",
    "    for _, erow in unresolved_edges.iterrows():\n",
    "        eid = int(erow[\"edge_id\"])\n",
    "        egeom = _as_linestring(erow[\"geometry\"])\n",
    "        best_len = 0.0\n",
    "        best_area = float(\"inf\")\n",
    "        best_prov = None\n",
    "        candidates = list(prov_sindex.intersection(egeom.bounds))\n",
    "        for ci in candidates:\n",
    "            pgeom = provinces_3395.geometry.iloc[int(ci)]\n",
    "            pname = provinces_3395[\"name\"].iloc[int(ci)]\n",
    "            parea = float(prov_areas[int(ci)])\n",
    "            try:\n",
    "                inter = egeom.intersection(pgeom)\n",
    "                if inter is None or inter.is_empty:\n",
    "                    continue\n",
    "                ilen = float(inter.length)\n",
    "                if ilen <= 0:\n",
    "                    continue\n",
    "                if (ilen > best_len + eps) or (abs(ilen - best_len) <= eps and parea < best_area):\n",
    "                    best_len = ilen\n",
    "                    best_area = parea\n",
    "                    best_prov = pname\n",
    "            except Exception:\n",
    "                continue\n",
    "        if best_prov is not None:\n",
    "            fallback_map[eid] = str(best_prov)\n",
    "print(f\"  Resolved by overlap fallback         : {len(fallback_map)}\")\n",
    "\n",
    "edge_province_map_all = dict(mid_best)\n",
    "edge_province_map_all.update(fallback_map)\n",
    "\n",
    "# --- Crossing detection: endpoints in different provinces (most-specific) ---\n",
    "pt_rows = []\n",
    "for eid, geom in zip(edges_3395[\"edge_id\"].tolist(), edges_3395[\"geometry\"].tolist()):\n",
    "    spt, ept = _endpoints(geom)\n",
    "    pt_rows.append({\"edge_id\": int(eid), \"which\": \"start\", \"geometry\": spt})\n",
    "    pt_rows.append({\"edge_id\": int(eid), \"which\": \"end\",   \"geometry\": ept})\n",
    "endpoints_3395 = gpd.GeoDataFrame(pt_rows, crs=\"EPSG:3395\")\n",
    "end_join = gpd.sjoin(\n",
    "    endpoints_3395,\n",
    "    provinces_3395[[\"name\", \"_prov_area\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"intersects\",\n",
    ")\n",
    "name_col_end = \"name_right\" if \"name_right\" in end_join.columns else \"name\"\n",
    "area_col_end = \"_prov_area_right\" if \"_prov_area_right\" in end_join.columns else \"_prov_area\"\n",
    "picked_end = _pick_most_specific(end_join, [\"edge_id\", \"which\"], name_col_end, area_col_end)\n",
    "start_map = {eid: picked_end.get((eid, \"start\")) for eid in edges_3395[\"edge_id\"].tolist()}\n",
    "end_map   = {eid: picked_end.get((eid, \"end\"))   for eid in edges_3395[\"edge_id\"].tolist()}\n",
    "\n",
    "crossing_edge_ids = set()\n",
    "for eid in edges_3395[\"edge_id\"].tolist():\n",
    "    sprov = start_map.get(int(eid))\n",
    "    eprov = end_map.get(int(eid))\n",
    "    if (sprov is None) or (eprov is None):\n",
    "        continue\n",
    "    if str(sprov) != str(eprov):\n",
    "        crossing_edge_ids.add(int(eid))\n",
    "\n",
    "# Final within-province assignment excludes crossing edges\n",
    "edge_province_map = {eid: prov for eid, prov in edge_province_map_all.items() if int(eid) not in crossing_edge_ids}\n",
    "\n",
    "all_edge_ids = set(edges_3395[\"edge_id\"].tolist())\n",
    "outside_edge_ids = all_edge_ids - set(edge_province_map_all.keys())\n",
    "\n",
    "# Province-counts table for exports\n",
    "province_counts_rows = []\n",
    "for eid in sorted(all_edge_ids):\n",
    "    eid = int(eid)\n",
    "    if eid in crossing_edge_ids:\n",
    "        provs = []\n",
    "        if start_map.get(eid) is not None:\n",
    "            provs.append(str(start_map[eid]))\n",
    "        if end_map.get(eid) is not None:\n",
    "            provs.append(str(end_map[eid]))\n",
    "        provs = sorted(set(provs))\n",
    "        province_counts_rows.append({\"edge_id\": eid, \"province_list\": provs, \"n_provinces\": len(provs)})\n",
    "    elif eid in edge_province_map_all:\n",
    "        province_counts_rows.append({\"edge_id\": eid, \"province_list\": [str(edge_province_map_all[eid])], \"n_provinces\": 1})\n",
    "    else:\n",
    "        province_counts_rows.append({\"edge_id\": eid, \"province_list\": [], \"n_provinces\": 0})\n",
    "province_counts = pd.DataFrame(province_counts_rows)\n",
    "\n",
    "print(f\"\\nEdge classification\")\n",
    "print(f\"  Total edges                  : {len(edges_clean_4326)}\")\n",
    "print(f\"  Within-province (kept)       : {len(edge_province_map)}\")\n",
    "print(f\"  Crossing border (excluded)   : {len(crossing_edge_ids)}\")\n",
    "print(f\"  Outside all polygons         : {len(outside_edge_ids)}\")\n",
    "\n",
    "# ── 3. Export weighted edge list with province assignment ─────────────────────\n",
    "_edge_cols = [\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\", \"weight\"]\n",
    "edges_for_export = edges_clean_3395.copy()\n",
    "keep_cols = [c for c in _edge_cols if c in edges_for_export.columns]\n",
    "if \"edge_id\" not in keep_cols:\n",
    "    raise RuntimeError(\"edges_clean_3395 is missing edge_id; can't export weighted edge list\")\n",
    "edges_for_export = edges_for_export[keep_cols].copy()\n",
    "edges_for_export[\"edge_id\"] = edges_for_export[\"edge_id\"].astype(int)\n",
    "if \"u_id\" in edges_for_export.columns:\n",
    "    edges_for_export[\"u_id\"] = edges_for_export[\"u_id\"].astype(int)\n",
    "if \"v_id\" in edges_for_export.columns:\n",
    "    edges_for_export[\"v_id\"] = edges_for_export[\"v_id\"].astype(int)\n",
    "\n",
    "edges_for_export[\"province\"] = edges_for_export[\"edge_id\"].map(edge_province_map_all)\n",
    "edges_for_export[\"province_start\"] = edges_for_export[\"edge_id\"].map(start_map)\n",
    "edges_for_export[\"province_end\"] = edges_for_export[\"edge_id\"].map(end_map)\n",
    "edges_for_export[\"is_crossing\"] = edges_for_export[\"edge_id\"].isin(crossing_edge_ids)\n",
    "edges_for_export[\"is_outside\"] = edges_for_export[\"edge_id\"].isin(outside_edge_ids)\n",
    "edges_for_export.to_csv(OUT_WEIGHTED_EDGES_PROV, index=False)\n",
    "print(f\"\\nSaved weighted edge list → {OUT_WEIGHTED_EDGES_PROV} ({len(edges_for_export)} edges)\")\n",
    "\n",
    "# ── 4. Save crossing & outside edges ─────────────────────────────────────────\n",
    "edges_map = edges_clean_4326.copy()\n",
    "edges_map[\"edge_id\"] = edges_map[\"edge_id\"].astype(int)\n",
    "edges_map[\"province\"] = edges_map[\"edge_id\"].map(edge_province_map)\n",
    "\n",
    "prov_info = province_counts.set_index(\"edge_id\")[[\"province_list\", \"n_provinces\"]]\n",
    "\n",
    "crossing_edges_4326 = edges_map[edges_map[\"edge_id\"].isin(crossing_edge_ids)].copy()\n",
    "ce_export = crossing_edges_4326.join(prov_info, on=\"edge_id\")\n",
    "ce_export[\"province_list\"] = ce_export[\"province_list\"].apply(lambda x: \";\".join(x) if isinstance(x, list) else \"\")\n",
    "ce_export.to_file(str(OUT_CROSSING_EDGES), driver=\"GeoJSON\")\n",
    "print(f\"\\nSaved crossing edges          → {OUT_CROSSING_EDGES}  ({len(ce_export)} edges)\")\n",
    "\n",
    "outside_edges_4326 = edges_map[edges_map[\"edge_id\"].isin(outside_edge_ids)].copy()\n",
    "outside_edges_4326.to_file(str(OUT_OUTSIDE_EDGES), driver=\"GeoJSON\")\n",
    "print(f\"Saved outside-province edges  → {OUT_OUTSIDE_EDGES}   ({len(outside_edges_4326)} edges)\")\n",
    "\n",
    "# ── 5. Build per-province sub-networks ───────────────────────────────────────\n",
    "province_names = sorted(set(edge_province_map.values()))\n",
    "print(f\"\\nProvinces with assigned edges: {len(province_names)}\")\n",
    "\n",
    "province_subgraphs = {}\n",
    "province_edge_tables = {}\n",
    "\n",
    "for pname in province_names:\n",
    "    prov_edge_ids = {eid for eid, pn in edge_province_map.items() if pn == pname}\n",
    "    sub_edges = [\n",
    "        (u, v, d) for u, v, d in G_clean.edges(data=True)\n",
    "        if int(d.get(\"edge_id\", -1)) in prov_edge_ids\n",
    "]\n",
    "    all_nodes = {n for u, v, _ in sub_edges for n in (u, v)}\n",
    "    G_sub = nx.Graph()\n",
    "    G_sub.add_nodes_from([(n, G_clean.nodes[n]) for n in all_nodes])\n",
    "    G_sub.add_edges_from(sub_edges)\n",
    "    province_subgraphs[pname] = G_sub\n",
    "    province_edge_tables[pname] = edges_map[edges_map[\"edge_id\"].isin(prov_edge_ids)].copy()\n",
    "\n",
    "print(f\"\\n{'Province':<35} {'Nodes':>6}  {'Edges':>6}  {'Components':>10}\")\n",
    "print(\"-\" * 65)\n",
    "for pname, Gsub in province_subgraphs.items():\n",
    "    n_comp = nx.number_connected_components(Gsub)\n",
    "    print(f\"{pname:<35} {Gsub.number_of_nodes():>6}  {Gsub.number_of_edges():>6}  {n_comp:>10}\")\n",
    "\n",
    "with open(OUT_PROVINCE_NETWORKS, \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"province_subgraphs\": province_subgraphs,\n",
    "            \"province_edge_tables\": province_edge_tables,\n",
    "            \"crossing_edge_ids\": list(crossing_edge_ids),\n",
    "            \"outside_edge_ids\": list(outside_edge_ids),\n",
    "            \"edge_province_map\": edge_province_map,\n",
    "        },\n",
    "        f,\n",
    "        protocol=pickle.HIGHEST_PROTOCOL,\n",
    "    )\n",
    "print(f\"\\nSaved province sub-networks → {OUT_PROVINCE_NETWORKS}\")\n",
    "\n",
    "# ── 6. Map (only: roads_with_provinces_nodes.html) ───────────────────────────\n",
    "_palette = list(mcolors.TABLEAU_COLORS.values()) + [\n",
    "    \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\", \"#aec7e8\", \"#ffbb78\",\n",
    "    \"#98df8a\", \"#ff9896\", \"#c5b0d5\", \"#c49c94\", \"#f7b6d2\", \"#c7c7c7\",\n",
    "]\n",
    "prov_colour = {row[\"name\"]: _palette[i % len(_palette)] for i, row in provinces_4326.iterrows()}\n",
    "\n",
    "# Simplify province boundaries for web display only (keeps HTML size down)\n",
    "PROVINCE_SIMPLIFY_TOL_M = 5000.0\n",
    "provinces_map_4326 = provinces_3395[[\"name\", \"geometry\"]].copy()\n",
    "provinces_map_4326[\"geometry\"] = provinces_map_4326.geometry.simplify(PROVINCE_SIMPLIFY_TOL_M, preserve_topology=True)\n",
    "provinces_map_4326 = provinces_map_4326.to_crs(epsg=4326)\n",
    "try:\n",
    "    provinces_map_4326[\"geometry\"] = provinces_map_4326.geometry.make_valid()\n",
    "except Exception:\n",
    "    provinces_map_4326[\"geometry\"] = provinces_map_4326.buffer(0)\n",
    "\n",
    "# Center (based on edges)\n",
    "_edges_3395_tmp = edges_map.to_crs(epsg=3395)\n",
    "center_3395 = _edges_3395_tmp.dissolve().centroid.iloc[0]\n",
    "center_4326 = gpd.GeoDataFrame(geometry=[center_3395], crs=\"EPSG:3395\").to_crs(epsg=4326)\n",
    "center_latlon = [float(center_4326.geometry.y.iloc[0]), float(center_4326.geometry.x.iloc[0])]\n",
    "\n",
    "# Precompute edge subsets used for mapping\n",
    "within_ids = set(edge_province_map.keys())\n",
    "within_edges = edges_map[edges_map[\"edge_id\"].isin(within_ids)].copy()\n",
    "within_edges[\"_color\"] = within_edges[\"province\"].map(lambda p: prov_colour.get(str(p), \"#1f77b4\"))\n",
    "crossing_edges = edges_map[edges_map[\"edge_id\"].isin(set(crossing_edge_ids))].copy()\n",
    "outside_edges  = edges_map[edges_map[\"edge_id\"].isin(set(outside_edge_ids))].copy()\n",
    "\n",
    "# Minimise properties embedded in the HTML GeoJSON (keeps file sizes sane)\n",
    "within_edges   = within_edges[[\"edge_id\", \"province\", \"_color\", \"geometry\"]].copy()\n",
    "crossing_edges = crossing_edges[[\"edge_id\", \"geometry\"]].copy()\n",
    "outside_edges  = outside_edges[[\"edge_id\", \"geometry\"]].copy()\n",
    "\n",
    "def _add_provinces(m):\n",
    "    fg = folium.FeatureGroup(name=\"Provinces\", show=True)\n",
    "    prov_gdf = provinces_map_4326 if \"provinces_map_4326\" in globals() else provinces_4326\n",
    "\n",
    "    def _style(feat):\n",
    "        pname = str(feat.get(\"properties\", {}).get(\"name\", \"\"))\n",
    "        c = prov_colour.get(pname, \"#888888\")\n",
    "        return {\n",
    "            \"fillColor\": c, \"color\": c,\n",
    "            \"weight\": 1.5, \"fillOpacity\": 0.18,\n",
    "        }\n",
    "\n",
    "    folium.GeoJson(\n",
    "        prov_gdf[[\"name\", \"geometry\"]].__geo_interface__,\n",
    "        style_function=_style,\n",
    "        tooltip=folium.GeoJsonTooltip(fields=[\"name\"], aliases=[\"province\"], sticky=True),\n",
    "    ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "def _add_roads_within(m):\n",
    "    fg = folium.FeatureGroup(name=\"Roads – inside province\", show=True)\n",
    "    folium.GeoJson(\n",
    "        within_edges.__geo_interface__,\n",
    "        style_function=lambda feat: {\n",
    "            \"color\": feat[\"properties\"].get(\"_color\", \"#1f77b4\"),\n",
    "            \"weight\": 2.5,\n",
    "            \"opacity\": 0.9,\n",
    "        },\n",
    "        tooltip=folium.GeoJsonTooltip(fields=[\"edge_id\", \"province\"], aliases=[\"edge_id\", \"province\"], sticky=True),\n",
    "    ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "def _add_roads_crossing(m):\n",
    "    fg = folium.FeatureGroup(name=\"Roads – crossing border (excluded)\", show=True)\n",
    "    folium.GeoJson(\n",
    "        crossing_edges.__geo_interface__,\n",
    "        style_function=lambda feat: {\n",
    "            \"color\": \"#d62728\",\n",
    "            \"weight\": 2.0,\n",
    "            \"opacity\": 0.85,\n",
    "            \"dashArray\": \"6,4\",\n",
    "        },\n",
    "        tooltip=folium.GeoJsonTooltip(fields=[\"edge_id\"], aliases=[\"edge_id\"], sticky=True),\n",
    "    ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "def _add_roads_outside(m):\n",
    "    fg = folium.FeatureGroup(name=\"Roads – outside all provinces\", show=False)\n",
    "    folium.GeoJson(\n",
    "        outside_edges.__geo_interface__,\n",
    "        style_function=lambda feat: {\n",
    "            \"color\": \"#aaaaaa\",\n",
    "            \"weight\": 1.0,\n",
    "            \"opacity\": 0.5,\n",
    "        },\n",
    "        tooltip=folium.GeoJsonTooltip(fields=[\"edge_id\"], aliases=[\"edge_id\"], sticky=True),\n",
    "    ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "def _add_nodes(m):\n",
    "    nodes = nodes_clean_4326\n",
    "    if nodes.crs is None:\n",
    "        nodes = nodes.set_crs(\"EPSG:4326\")\n",
    "    else:\n",
    "        nodes = nodes.to_crs(epsg=4326)\n",
    "    coords = [[float(p.y), float(p.x)] for p in nodes.geometry if p is not None and not p.is_empty]\n",
    "    fg = folium.FeatureGroup(name=\"Network nodes (G_clean)\", show=True)\n",
    "    for lat, lon in coords:\n",
    "        folium.CircleMarker(\n",
    "            location=[lat, lon],\n",
    "            radius=3,\n",
    "            weight=3,\n",
    "            color=\"#2ca02c\",\n",
    "            opacity=1.0,\n",
    "            fill=True,\n",
    "            fill_color=\"#2ca02c\",\n",
    "            fill_opacity=0.9,\n",
    "        ).add_to(fg)\n",
    "    fg.add_to(m)\n",
    "\n",
    "m_prov_nodes = folium.Map(location=center_latlon, zoom_start=6, tiles=\"CartoDB positron\")\n",
    "_add_provinces(m_prov_nodes)\n",
    "_add_roads_within(m_prov_nodes)\n",
    "_add_roads_crossing(m_prov_nodes)\n",
    "_add_roads_outside(m_prov_nodes)\n",
    "_add_nodes(m_prov_nodes)\n",
    "folium.LayerControl(collapsed=False).add_to(m_prov_nodes)\n",
    "m_prov_nodes.save(str(OUT_PROVINCE_MAP_NODES))\n",
    "print(f\"Saved province overlay + nodes → {OUT_PROVINCE_MAP_NODES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b45fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
