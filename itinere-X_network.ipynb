{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7822867",
   "metadata": {},
   "source": [
    "# Building the Roman Road Network using itiner-e dataset\n",
    "This notebook builds the Roman Road Network (RRN) using functions from `itinerex_clean_network.py` and the data originally released as part of the `[Nature](https://www.nature.com/articles/s41597-025-06140-z)` publication. \n",
    "\n",
    "It produces:\n",
    "- `roads_before_cleaning.html`: raw roads from GeoJSON (display only)\n",
    "- `roads_after_cleaning.html`: cleaned, noded, degree-2 simplified network with **node_id** and **edge_id** shown on the map\n",
    "- `G_clean_weighted_with_ids.pkl`: pickle containing the cleaned weighted graph + node/edge tables for mapping analysis results back to geometry/CRS.\n",
    "\n",
    "All metric operations run in **EPSG:3395**; maps are displayed in **EPSG:4326**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfdb1ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfolium\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitinerex_clean_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01micn\u001b[39;00m\n\u001b[32m     13\u001b[39m importlib.reload(icn)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/itinerex_clean_network.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshapely\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m snap \u001b[38;5;28;01mas\u001b[39;00m shapely_snap\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DBSCAN  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m     16\u001b[39m     DBSCAN = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/__init__.py:70\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build, _distributor_init  \u001b[38;5;66;03m# noqa: E402 F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     73\u001b[39m _submodules = [\n\u001b[32m     74\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/base.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_pandas_na, is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/utils/__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, resample, shuffle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/utils/_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:24\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     DataConversionWarning,\n\u001b[32m     21\u001b[39m     NotFittedError,\n\u001b[32m     22\u001b[39m     PositiveSpectrumWarning,\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     _asarray_with_order,\n\u001b[32m     26\u001b[39m     _convert_to_numpy,\n\u001b[32m     27\u001b[39m     _is_numpy_namespace,\n\u001b[32m     28\u001b[39m     _max_precision_float_dtype,\n\u001b[32m     29\u001b[39m     get_namespace,\n\u001b[32m     30\u001b[39m     get_namespace_and_device,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_pandas_df, is_pandas_df_or_series\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_isfinite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_df_or_series\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[32m     23\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mxpx\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/sklearn/utils/fixes.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/scipy/sparse/linalg/__init__.py:132\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m==================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_isolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dsolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterative\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mminres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlgmres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/iterative.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_system\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[32m      7\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mbicg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbicgstab\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcgs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgmres\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mqmr\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_atol_rtol\u001b[39m(name, b_norm, atol=\u001b[32m0.\u001b[39m, rtol=\u001b[32m1e-5\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/itinereX/.venv/lib/python3.11/site-packages/scipy/linalg/__init__.py:208\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp_ldl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp_cholesky\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp_qr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp_qz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decomp_svd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:936\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1032\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1130\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import folium\n",
    "\n",
    "import importlib\n",
    "import itinerex_clean_network as icn\n",
    "importlib.reload(icn)\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "GEOJSON_PATH = Path(\"17122148/itinere_roads.geojson\")\n",
    "\n",
    "# These tolerances are in meters (EPSG:3395).\n",
    "SNAP_TOL_M = 240.0\n",
    "MERGE_DEG1_TOL_M = 240.0\n",
    "\n",
    "# Constant-speed time weights (matches earlier baseline).\n",
    "BASE_SPEED_KMH = 2.0\n",
    "WEIGHT_MODE = \"time\"  # sets edge attribute 'weight' = travel time (seconds)\n",
    "\n",
    "OUT_BEFORE_HTML = Path(\"roads_before_cleaning.html\")\n",
    "OUT_AFTER_HTML = Path(\"roads_after_cleaning.html\")\n",
    "OUT_PICKLE = Path(\"G_clean_weighted_with_ids.pkl\")\n",
    "\n",
    "\n",
    "def _union_all(gs):\n",
    "    \"\"\"GeoSeries union helper compatible with Shapely 2 / older GeoPandas.\"\"\"\n",
    "    try:\n",
    "        return gs.union_all()\n",
    "    except Exception:\n",
    "        return gs.unary_union\n",
    "\n",
    "\n",
    "def _node_id_mapping(G: nx.Graph):\n",
    "    \"\"\"Assign stable node_ids (1..N) by sorting coordinates.\"\"\"\n",
    "    nodes = [(float(x), float(y)) for (x, y) in G.nodes()]\n",
    "    nodes_sorted = sorted(nodes, key=lambda xy: (xy[0], xy[1]))\n",
    "    node_to_id = {xy: i + 1 for i, xy in enumerate(nodes_sorted)}\n",
    "    id_to_node = {i: xy for xy, i in node_to_id.items()}\n",
    "    return node_to_id, id_to_node\n",
    "\n",
    "\n",
    "def _edge_id_mapping(G: nx.Graph, node_to_id: dict[tuple[float, float], int]):\n",
    "    \"\"\"Assign stable edge_ids (1..M) by sorting undirected (u_id, v_id).\"\"\"\n",
    "    pairs = []\n",
    "    for u, v in G.edges():\n",
    "        uid = int(node_to_id[(float(u[0]), float(u[1]))])\n",
    "        vid = int(node_to_id[(float(v[0]), float(v[1]))])\n",
    "        a, b = (uid, vid) if uid <= vid else (vid, uid)\n",
    "        pairs.append((a, b, (u, v)))\n",
    "    pairs_sorted = sorted(pairs, key=lambda t: (t[0], t[1]))\n",
    "    edge_key_to_id = {(a, b): i + 1 for i, (a, b, _) in enumerate(pairs_sorted)}\n",
    "    return edge_key_to_id\n",
    "\n",
    "\n",
    "def graph_to_tables(G: nx.Graph, crs_3395: str = \"EPSG:3395\"):\n",
    "    \"\"\"Return (nodes_gdf_3395, edges_gdf_3395, nodes_gdf_4326, edges_gdf_4326).\"\"\"\n",
    "    node_to_id, id_to_node = _node_id_mapping(G)\n",
    "    edge_key_to_id = _edge_id_mapping(G, node_to_id)\n",
    "\n",
    "    # Nodes\n",
    "    deg = dict(G.degree())\n",
    "    rows_n = []\n",
    "    for xy, node_id in node_to_id.items():\n",
    "        x, y = float(xy[0]), float(xy[1])\n",
    "        rows_n.append({\n",
    "            \"node_id\": int(node_id),\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"degree\": int(deg.get(xy, 0)),\n",
    "        })\n",
    "    nodes_3395 = gpd.GeoDataFrame(\n",
    "        rows_n,\n",
    "        geometry=gpd.points_from_xy([r[\"x\"] for r in rows_n], [r[\"y\"] for r in rows_n]),\n",
    "        crs=crs_3395,\n",
    "    )\n",
    "    nodes_4326 = nodes_3395.to_crs(epsg=4326)\n",
    "\n",
    "    # Edges (requires 'geometry' on graph edges)\n",
    "    rows_e = []\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        u = (float(u[0]), float(u[1]))\n",
    "        v = (float(v[0]), float(v[1]))\n",
    "        uid = int(node_to_id[u])\n",
    "        vid = int(node_to_id[v])\n",
    "        a, b = (uid, vid) if uid <= vid else (vid, uid)\n",
    "        edge_id = int(edge_key_to_id[(a, b)])\n",
    "        rows_e.append({\n",
    "            \"edge_id\": edge_id,\n",
    "            \"u_id\": uid,\n",
    "            \"v_id\": vid,\n",
    "            \"weight\": float(d.get(\"weight\", 1.0)),\n",
    "            \"time_s\": float(d.get(\"time_s\", d.get(\"weight\", np.nan))),\n",
    "            \"dist_m\": float(d.get(\"dist_m\", np.nan)),\n",
    "            \"geometry\": d.get(\"geometry\"),\n",
    "        })\n",
    "    edges_3395 = gpd.GeoDataFrame(rows_e, crs=crs_3395)\n",
    "    edges_3395 = edges_3395[edges_3395.geometry.notna() & ~edges_3395.geometry.is_empty].copy()\n",
    "    edges_4326 = edges_3395.to_crs(epsg=4326)\n",
    "\n",
    "    return nodes_3395, edges_3395, nodes_4326, edges_4326, node_to_id, id_to_node, edge_key_to_id\n",
    "\n",
    "\n",
    "def save_before_map(roads_4326: gpd.GeoDataFrame, out_html: Path, simplify_tol_m: float = 50.0):\n",
    "    \"\"\"Save a lightweight BEFORE map.\n",
    "\n",
    "    The raw roads are often too large to embed feature-by-feature in a Folium HTML.\n",
    "    We project to EPSG:3395, simplify in meters, dissolve into one geometry, then map that.\n",
    "    \"\"\"\n",
    "    if roads_4326 is None or len(roads_4326) == 0:\n",
    "        raise ValueError(\"No roads to plot\")\n",
    "\n",
    "    roads_m = roads_4326.to_crs(epsg=3395)\n",
    "    simp = roads_m.geometry.simplify(float(simplify_tol_m), preserve_topology=True)\n",
    "    merged_m = _union_all(simp)\n",
    "    merged_4326 = gpd.GeoDataFrame({\"geometry\": [merged_m]}, crs=\"EPSG:3395\").to_crs(epsg=4326)\n",
    "\n",
    "    center = merged_4326.geometry.iloc[0].centroid\n",
    "    m = folium.Map(location=[float(center.y), float(center.x)], zoom_start=6, tiles=\"CartoDB positron\")\n",
    "    folium.GeoJson(merged_4326.__geo_interface__, name=\"Roads (raw, simplified)\").add_to(m)\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    m.save(str(out_html))\n",
    "    return out_html\n",
    "\n",
    "\n",
    "def save_after_map(edges_4326: gpd.GeoDataFrame, nodes_4326: gpd.GeoDataFrame, out_html: Path):\n",
    "    if (edges_4326 is None or len(edges_4326) == 0) and (nodes_4326 is None or len(nodes_4326) == 0):\n",
    "        raise ValueError(\"No cleaned nodes/edges to plot\")\n",
    "    if edges_4326 is not None and len(edges_4326):\n",
    "        center = _union_all(edges_4326.geometry).centroid\n",
    "    else:\n",
    "        center = _union_all(nodes_4326.geometry).centroid\n",
    "    m = folium.Map(location=[float(center.y), float(center.x)], zoom_start=6, tiles=\"CartoDB positron\")\n",
    "\n",
    "    fg_edges = folium.FeatureGroup(name=\"Edges (cleaned)\", show=True)\n",
    "    fg_nodes = folium.FeatureGroup(name=\"Nodes (cleaned)\", show=True)\n",
    "    m.add_child(fg_edges)\n",
    "    m.add_child(fg_nodes)\n",
    "\n",
    "    use_edges = edges_4326.copy()\n",
    "    for col in [\"edge_id\", \"u_id\", \"v_id\"]:\n",
    "        use_edges[col] = use_edges[col].astype(int)\n",
    "    if \"time_s\" in use_edges.columns:\n",
    "        use_edges[\"time_s\"] = use_edges[\"time_s\"].astype(float)\n",
    "    if \"dist_m\" in use_edges.columns:\n",
    "        use_edges[\"dist_m\"] = use_edges[\"dist_m\"].astype(float)\n",
    "    folium.GeoJson(\n",
    "        use_edges.__geo_interface__,\n",
    "        name=\"Edges (cleaned)\",\n",
    "        tooltip=folium.GeoJsonTooltip(\n",
    "            fields=[\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\"],\n",
    "            aliases=[\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\"],\n",
    "            sticky=True,\n",
    "        ),\n",
    "    ).add_to(fg_edges)\n",
    "\n",
    "    for row in nodes_4326.itertuples(index=False):\n",
    "        lat = float(row.geometry.y)\n",
    "        lon = float(row.geometry.x)\n",
    "        folium.CircleMarker(\n",
    "            location=(lat, lon),\n",
    "            radius=3,\n",
    "            color=\"#2ca02c\",\n",
    "            fill=True,\n",
    "            fill_opacity=0.9,\n",
    "            tooltip=f\"node_id={int(row.node_id)} deg={int(row.degree)}\",\n",
    "        ).add_to(fg_nodes)\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    m.save(str(out_html))\n",
    "    return out_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554b581",
   "metadata": {},
   "source": [
    "# 1) Load raw roads + BEFORE map\n",
    "Loads the input roads GeoJSON, projects to EPSG:3395 for metric operations, and saves a raw “before cleaning” HTML map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52bb0641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roads_4326: 14769 features\n",
      "roads_3395 CRS: EPSG:3395\n",
      "Saved: roads_before_cleaning.html\n"
     ]
    }
   ],
   "source": [
    "# Load (keep a 4326 copy for mapping)\n",
    "roads_4326 = gpd.read_file(GEOJSON_PATH)\n",
    "roads_4326 = roads_4326[roads_4326.geometry.notna() & ~roads_4326.geometry.is_empty].copy()\n",
    "roads_4326 = roads_4326[roads_4326.geometry.geom_type.isin([\"LineString\", \"MultiLineString\"])].copy()\n",
    "roads_4326 = roads_4326.reset_index(drop=True)\n",
    "\n",
    "# Project for cleaning operations\n",
    "roads_3395 = roads_4326.to_crs(epsg=3395)\n",
    "print(\"roads_4326:\", len(roads_4326), \"features\")\n",
    "print(\"roads_3395 CRS:\", roads_3395.crs)\n",
    "\n",
    "out_before = save_before_map(roads_4326, OUT_BEFORE_HTML)\n",
    "print(\"Saved:\", out_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5bbbd7",
   "metadata": {},
   "source": [
    "# 2) Clean rebuild + AFTER map + export\n",
    "Builds a cleaned topology from the raw GeoJSON using `itinerex_clean_network.build_clean_network_from_geojson()`, assigns stable `node_id`/`edge_id`, saves an “after cleaning” HTML map with those IDs, and exports everything as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f659b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] load...\n",
      "[2/10] prepare...\n",
      "[3/10] snap...\n",
      "Snapping line endpoints to nearby linework\n",
      "[4/10] node...\n",
      "[5/10] segmentize...\n",
      "Converting lines to segments\n",
      "[6/10] graph...\n",
      "Building graph from segments\n",
      "[7/10] merge_deg1...\n",
      "[8/10] simplify_deg2...\n",
      "Simplifying degree-2 nodes\n",
      "{'snap_tol_m': 240.0, 'near_miss_before': {'skipped': 1}, 'near_miss_after': {'skipped': 1}, 'noded_lines': 16851, 'segments': 1001619, 'graph_nodes': 8460, 'graph_edges': 12849, 'deg2_nodes': 0, 'deg1_nodes': 833, 'timings_s': {'load': 2.187076583999442, 'prepare': 0.044336041988572106, 'snap': 1.8756986249936745, 'node': 1.0297277079953346, 'segmentize': 4.22618749999674, 'graph': 11.450567542022327, 'merge_deg1': 20.09908716598875, 'simplify_deg2': 13.094379540998489}, 'snap_method': 'endpoints', 'diagnose': False, 'diagnose_max_endpoints': None, 'merge_deg1': {'enabled': 1, 'deg1_before': 998, 'deg1_after': 829, 'clusters': 81, 'merged_nodes': 173}, 'base_speed_kmh': 2.0, 'weight_mode': 'time'}\n",
      "G_clean: 8460 nodes; 12849 edges\n",
      "Example edge attrs: {'weight': 4021.520454095041, 'dist_m': 2234.1780300528008, 'time_s': 4021.520454095041, 'geometry': <LINESTRING (2595776.094 4597595.392, 2595762.057 4597411.293, 2595687.194 4...>}\n",
      "nodes_clean_3395: 8460 rows\n",
      "edges_clean_3395: 12849 rows\n"
     ]
    }
   ],
   "source": [
    "# Build cleaned network (EPSG:3395 metric topology)\n",
    "res = icn.build_clean_network_from_geojson(\n",
    "    str(GEOJSON_PATH),\n",
    "    snap_tol_m=float(SNAP_TOL_M),\n",
    "    snap_method=\"endpoints\",\n",
    "    diagnose=False,\n",
    "    merge_deg1_tol_m=float(MERGE_DEG1_TOL_M),\n",
    "    merge_deg1_min_samples=2,\n",
    "    simplify_deg2=True,\n",
    "    base_speed_kmh=float(BASE_SPEED_KMH),\n",
    "    weight_mode=str(WEIGHT_MODE),\n",
    "    show_progress=True,\n",
    " )\n",
    "\n",
    "print(res.diagnostics)\n",
    "\n",
    "G_clean: nx.Graph = res.graph\n",
    "segments_clean_3395: gpd.GeoDataFrame = res.segments_m\n",
    "noded_lines_clean_3395: gpd.GeoDataFrame = res.noded_lines_m\n",
    "\n",
    "print(\"G_clean:\", G_clean.number_of_nodes(), \"nodes;\", G_clean.number_of_edges(), \"edges\")\n",
    "print(\"Example edge attrs:\", next(iter(G_clean.edges(data=True)))[2])\n",
    "\n",
    "# Assign stable IDs and create node/edge tables (both 3395 + 4326)\n",
    "nodes_clean_3395, edges_clean_3395, nodes_clean_4326, edges_clean_4326, node_to_id, id_to_node, edge_key_to_id = graph_to_tables(\n",
    "    G_clean, crs_3395=\"EPSG:3395\"\n",
    " )\n",
    "\n",
    "# Attach node_id/edge_id onto the graph too (for routing + analysis)\n",
    "for xy, node_id in node_to_id.items():\n",
    "    if xy in G_clean:\n",
    "        G_clean.nodes[xy][\"node_id\"] = int(node_id)\n",
    "\n",
    "for u, v, d in G_clean.edges(data=True):\n",
    "    uid = int(node_to_id[(float(u[0]), float(u[1]))])\n",
    "    vid = int(node_to_id[(float(v[0]), float(v[1]))])\n",
    "    a, b = (uid, vid) if uid <= vid else (vid, uid)\n",
    "    d[\"edge_id\"] = int(edge_key_to_id[(a, b)])\n",
    "    d[\"u_id\"] = uid\n",
    "    d[\"v_id\"] = vid\n",
    "\n",
    "print(\"nodes_clean_3395:\", len(nodes_clean_3395), \"rows\")\n",
    "print(\"edges_clean_3395:\", len(edges_clean_3395), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ee111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: roads_after_cleaning.html\n"
     ]
    }
   ],
   "source": [
    "# Save AFTER map (cleaned network) with node_id / edge_id tooltips\n",
    "out_after = save_after_map(edges_clean_4326, nodes_clean_4326, OUT_AFTER_HTML)\n",
    "print(\"Saved:\", out_after)\n",
    "\n",
    "# # Display inline map object\n",
    "# m_after = folium.Map(location=[float(nodes_clean_4326.geometry.y.mean()), float(nodes_clean_4326.geometry.x.mean())], zoom_start=6, tiles=\"CartoDB positron\")\n",
    "# folium.GeoJson(\n",
    "#     edges_clean_4326.__geo_interface__,\n",
    "#     name=\"Edges (cleaned)\",\n",
    "#     tooltip=folium.GeoJsonTooltip(fields=[\"edge_id\", \"u_id\", \"v_id\", \"time_s\", \"dist_m\"], sticky=True),\n",
    "# ).add_to(m_after)\n",
    "# for row in nodes_clean_4326.itertuples(index=False):\n",
    "#     folium.CircleMarker(\n",
    "#         location=(float(row.geometry.y), float(row.geometry.x)),\n",
    "#         radius=3,\n",
    "#         color=\"#2ca02c\",\n",
    "#         fill=True,\n",
    "#         fill_opacity=0.9,\n",
    "#         tooltip=f\"node_id={int(row.node_id)} deg={int(row.degree)}\",\n",
    "#     ).add_to(m_after)\n",
    "# folium.LayerControl(collapsed=False).add_to(m_after)\n",
    "# m_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e32713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes                              : 8460\n",
      "edges                              : 12849\n",
      "avg_degree                         : 3.0375886524822695\n",
      "avg_weighted_degree                : 167930.63592041272\n",
      "connected_components               : 12\n",
      "largest_component_nodes            : 7612\n",
      "largest_component_edges            : 11693\n",
      "largest_component_fraction_of_nodes: 0.8997635933806146\n"
     ]
    }
   ],
   "source": [
    "def graph_stats(G: nx.Graph, weight: str | None = \"weight\"):\n",
    "    \"\"\"Basic graph stats + (optional) weighted degree (strength).\"\"\"\n",
    "    n = int(G.number_of_nodes())\n",
    "    m = int(G.number_of_edges())\n",
    "    avg_deg = (2.0 * m / n) if n else 0.0\n",
    "\n",
    "    if weight is None:\n",
    "        wdeg = dict(G.degree())\n",
    "    else:\n",
    "        if m and not any((weight in d) for _, _, d in G.edges(data=True)):\n",
    "            print(f\"WARNING: edge attribute '{weight}' not found on any edge; weighted degree will equal unweighted degree.\")\n",
    "        wdeg = dict(G.degree(weight=weight))\n",
    "    avg_wdeg = float(np.mean(list(wdeg.values()))) if n else 0.0\n",
    "\n",
    "    comps = list(nx.connected_components(G))\n",
    "    num_cc = int(len(comps))\n",
    "    largest_cc_size = int(max((len(c) for c in comps), default=0))\n",
    "    if largest_cc_size:\n",
    "        largest_nodes = max(comps, key=len)\n",
    "        G_lcc = G.subgraph(largest_nodes)\n",
    "        lcc_edges = int(G_lcc.number_of_edges())\n",
    "        lcc_frac = float(largest_cc_size / n)\n",
    "    else:\n",
    "        lcc_edges = 0\n",
    "        lcc_frac = 0.0\n",
    "\n",
    "    return {\n",
    "        \"nodes\": n,\n",
    "        \"edges\": m,\n",
    "        \"avg_degree\": float(avg_deg),\n",
    "        \"avg_weighted_degree\": float(avg_wdeg),\n",
    "        \"connected_components\": num_cc,\n",
    "        \"largest_component_nodes\": largest_cc_size,\n",
    "        \"largest_component_edges\": lcc_edges,\n",
    "        \"largest_component_fraction_of_nodes\": float(lcc_frac),\n",
    "    }\n",
    "\n",
    "stats = graph_stats(G_clean, weight=\"weight\")\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k:35s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b83d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/nk821/Documents/GitHub/itinereX/G_clean_weighted_with_ids.pkl\n"
     ]
    }
   ],
   "source": [
    "# Export cleaned weighted network + mapping tables\n",
    "\n",
    "# NOTE on portability:\n",
    "# Pickling raw NetworkX graphs can be brittle across Python/NetworkX versions.\n",
    "# This export is reconstruction-friendly: it stores node/edge tables + an edge list.\n",
    "\n",
    "edges_export_3395 = edges_clean_3395.copy()\n",
    "try:\n",
    "    edges_export_3395[\"geometry_wkt\"] = edges_export_3395.geometry.to_wkt()\n",
    "except Exception:\n",
    "    edges_export_3395[\"geometry_wkt\"] = edges_export_3395.geometry.apply(lambda g: g.wkt if g is not None else None)\n",
    "\n",
    "nodes_export_3395 = nodes_clean_3395.copy()\n",
    "try:\n",
    "    nodes_export_3395[\"geometry_wkt\"] = nodes_export_3395.geometry.to_wkt()\n",
    "except Exception:\n",
    "    nodes_export_3395[\"geometry_wkt\"] = nodes_export_3395.geometry.apply(lambda g: g.wkt if g is not None else None)\n",
    "\n",
    "export = {\n",
    "    \"crs_metric\": \"EPSG:3395\",\n",
    "    \"crs_map\": \"EPSG:4326\",\n",
    "    \"params\": {\n",
    "        \"geojson\": str(GEOJSON_PATH),\n",
    "        \"snap_tol_m\": float(SNAP_TOL_M),\n",
    "        \"merge_deg1_tol_m\": float(MERGE_DEG1_TOL_M),\n",
    "        \"base_speed_kmh\": float(BASE_SPEED_KMH),\n",
    "        \"weight_mode\": str(WEIGHT_MODE),\n",
    "    },\n",
    "    # Full GeoDataFrames (with shapely geometries)\n",
    "    \"nodes_3395\": nodes_export_3395,\n",
    "    \"edges_3395\": edges_export_3395,\n",
    "    \"nodes_4326\": nodes_clean_4326,\n",
    "    \"edges_4326\": edges_clean_4326,\n",
    "    # Reconstruction-friendly tables (no shapely dependency required if using WKT)\n",
    "    \"node_table\": nodes_export_3395.drop(columns=[\"geometry\"], errors=\"ignore\"),\n",
    "    \"edge_table\": edges_export_3395.drop(columns=[\"geometry\"], errors=\"ignore\"),\n",
    "    # Stable mappings\n",
    "    \"node_to_id\": node_to_id,\n",
    "    \"id_to_node\": id_to_node,\n",
    "}\n",
    "\n",
    "with open(OUT_PICKLE, \"wb\") as f:\n",
    "    pickle.dump(export, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saved:\", OUT_PICKLE.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
